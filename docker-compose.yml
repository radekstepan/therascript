# Defines and orchestrates the Whisper and Elasticsearch service containers for the Therascript application.
# Ollama is managed by a separate compose file in `packages/ollama/docker-compose.yml`.

services:
  # Whisper Transcription Service (Existing)
  whisper:
    build:
      context: .
      dockerfile: packages/whisper/Dockerfile
    image: therascript/whisper
    container_name: therascript_whisper_service
    ports:
      - "127.0.0.1:8000:8000"
    volumes:
      - ./packages/whisper/.cache:/root/.cache
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8000/health"]
      interval: 15s
      timeout: 5s
      retries: 3
      start_period: 30s

  # --- VOXTRAL SERVICE (Corrected to be a full executable command) ---
  voxtral:
    build:
      context: .
      dockerfile: packages/voxtral/Dockerfile
      args:
        - HUGGING_FACE_HUB_TOKEN=${HUGGING_FACE_HUB_TOKEN}
    image: therascript/voxtral
    container_name: therascript_voxtral_service
    environment:
      - VLLM_USE_TRITON=0
      - CUDA_VISIBLE_DEVICES=0
    command:
      - "python3"
      - "-m"
      - "vllm.entrypoints.openai.api_server"
      - "--model"
      - "mistralai/Voxtral-Mini-3B-2507"
      - "--tokenizer_mode"
      - "mistral"
      - "--config_format"
      - "mistral" 
      - "--load_format"
      - "mistral"
      - "--host"
      - "0.0.0.0"
      - "--port"
      - "8000"
      - "--gpu-memory-utilization"
      - "0.80"
    ports:
      - "127.0.0.1:8001:8000"
    volumes:
      - voxtral_models:/root/.cache/huggingface
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8000/v1/models"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 300s

  # Elasticsearch Service
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.14.1
    container_name: therascript_elasticsearch_service
    environment:
      - discovery.type=single-node
      - ES_JAVA_OPTS=-Xms512m -Xmx512m
      - xpack.security.enabled=false
      - TAKE_FILE_OWNERSHIP=true
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    ports:
      - "127.0.0.1:9200:9200"
    volumes:
      - es_data:/usr/share/elasticsearch/data
    healthcheck:
      test: ["CMD-SHELL", "curl -fsSL http://localhost:9200/_cat/health?h=status | grep -q 'green\\|yellow'"]
      interval: 10s
      timeout: 10s
      retries: 10
      start_period: 120s

  # Kibana Service
  kibana:
    image: docker.elastic.co/kibana/kibana:8.14.1
    container_name: therascript_kibana_service
    environment:
      - ELASTICSEARCH_HOSTS=http://therascript_elasticsearch_service:9200
    ports:
      - "127.0.0.1:5601:5601"
    depends_on:
      elasticsearch:
        condition: service_healthy
    restart: unless-stopped

volumes:
  es_data:
    driver: local
  voxtral_models:
    driver: local
