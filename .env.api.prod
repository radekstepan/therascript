# File: .env.api.prod
# ==========================================================
# PRODUCTION Environment for Therascript API
# ==========================================================

# === General Server Configuration ===
# Use a standard production port or one suitable for your deployment
PORT=8080
NODE_ENV=production
APP_MODE=production # <= Use real services
# CHANGE THIS to your actual frontend domain
CORS_ORIGIN=https://your-frontend-domain.com

# --- Ollama Configuration ---
# Point to your production Ollama instance URL
OLLAMA_BASE_URL=http://localhost:11434 # Or http://<ollama_server_ip>:11434
# Use the desired production model
OLLAMA_MODEL=gemma3:12b-it-qat # Or your preferred large model
# Keep models loaded longer in production, adjust as needed
OLLAMA_CHAT_KEEP_ALIVE=60m # Or -1 for infinite

# --- Whisper Configuration ---
# Point to your production Whisper instance URL
WHISPER_API_URL=http://localhost:8000 # Or http://<whisper_server_ip>:8000
# Use a high-quality model for production
WHISPER_MODEL=large # Or 'medium'

# --- Database & File Storage Configuration ---
# (Relative to packages/api) - Use appropriate production paths
DB_PATH=/var/data/therascript/therapy-analyzer.sqlite # Example production path
DB_TRANSCRIPTS_DIR=/var/data/therascript/transcripts
DB_UPLOADS_DIR=/var/data/therascript/uploads

# --- Upload Configuration ---
UPLOAD_MAX_FILE_SIZE=1g # Adjust if needed

# --- Mock Mode Specific Configuration (Ignored) ---
# MOCK_WHISPER_DELAY_MS=500
# MOCK_OLLAMA_DELAY_MS=800
# MOCK_LLM_MODEL_NAME=mock-llama3:latest
