# Purpose: Production environment configuration for the Therascript API (`packages/api`).
# Usage: Loaded via `node --env-file=.env.api.prod ...` (see root package.json `start:api` script or systemd service).
#        **Ensure these values are set correctly and securely for your production deployment.**
# ==========================================================
# PRODUCTION Environment for Therascript API
# ==========================================================

# === General Server Configuration ===
# Standard production port (e.g., 80, 443 if behind proxy, or a high port like 8080).
PORT=3001
# Sets Node.js environment to production (disables verbose logging, stack traces, etc.).
NODE_ENV=production
# Application mode - 'production' uses REAL backend services.
APP_MODE=production
# IMPORTANT: Change this to your actual frontend domain for CORS security. '*' is insecure.
CORS_ORIGIN=http://localhost:3002 # e.g., https://app.therascript.com

# --- Ollama Configuration ---
# URL of your production Ollama instance. Could be localhost if running on the same server,
# or the IP/domain of a dedicated Ollama server.
OLLAMA_BASE_URL=http://localhost:11434 # Example: http://192.168.1.100:11434
# Choose the desired production-grade LLM. Ensure it's pulled on the Ollama server.
OLLAMA_MODEL=gemma3:12b-it-qat # Example: llama3:70b, mixtral:latest
# Keep models loaded for longer in production to avoid reload delays.
# '-1' means keep loaded indefinitely (until Ollama server restarts). Adjust based on RAM.
OLLAMA_CHAT_KEEP_ALIVE=60m # Example: 60 minutes

# === NEW: Transcription Service Selection ===
# Select the transcription service to use for this environment.
# Options: 'whisper' (default async job-based service) or 'voxtral' (new sync service).
TRANSCRIPTION_SERVICE=voxtral

# --- Whisper Configuration (used if TRANSCRIPTION_SERVICE='whisper') ---
# URL of your production Whisper service instance.
WHISPER_API_URL=http://localhost:8000 # Example: http://192.168.1.101:8000
# Use a high-quality Whisper model for better accuracy in production.
# Options: 'tiny', 'base', 'small', 'medium', 'large' (or variants like 'large-v3').
WHISPER_MODEL=large # Or 'large-v3'

# --- Voxtral Configuration (used if TRANSCRIPTION_SERVICE='voxtral') ---
# URL where the Voxtral service Docker container is accessible in production.
VOXTRAL_API_URL=http://localhost:8001

# --- Elasticsearch Configuration ---
ELASTICSEARCH_URL=http://localhost:9200

# --- Database & File Storage Configuration ---
# Paths should be ABSOLUTE paths suitable for your production server environment.
# Ensure the user running the Node.js process has read/write permissions to these directories.
# Paths are RELATIVE to the `packages/api` directory *if left relative*, but absolute paths are recommended for production.
DB_PATH=./data/therapy-analyzer-prod.sqlite # Example absolute path
DB_TRANSCRIPTS_DIR=./data/transcripts  # Example absolute path (currently unused)
DB_UPLOADS_DIR=./data/uploads          # Example absolute path

# --- Upload Configuration ---
# Maximum allowed upload size. Ensure web server (e.g., Nginx) is also configured to allow this size.
UPLOAD_MAX_FILE_SIZE=1g # Example: 1 Gigabyte

# --- Mock Mode Specific Configuration (Ignored in production) ---
# These have no effect when APP_MODE=production.
# MOCK_WHISPER_DELAY_MS=500
# MOCK_OLLAMA_DELAY_MS=800
# MOCK_LLM_MODEL_NAME=mock-llama3:latest
